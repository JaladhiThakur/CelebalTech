{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQvtFbWr-APL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "033e651d-205c-44e0-f474-18c415aa986a"
      },
      "source": [
        "#KNN algorithm\r\n",
        "\r\n",
        "# Import necessary modules \r\n",
        "from sklearn.neighbors import KNeighborsClassifier \r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "from sklearn.datasets import load_iris \r\n",
        "\r\n",
        "# Loading data \r\n",
        "irisData = load_iris() \r\n",
        "\r\n",
        "# Create feature and target arrays \r\n",
        "X = irisData.data \r\n",
        "y = irisData.target \r\n",
        "\r\n",
        "# Split into training and test set \r\n",
        "X_train, X_test, y_train, y_test = train_test_split( \r\n",
        "\t\t\tX, y, test_size = 0.2, random_state=42) \r\n",
        "\r\n",
        "knn = KNeighborsClassifier(n_neighbors=7) \r\n",
        "\r\n",
        "knn.fit(X_train, y_train) \r\n",
        "\r\n",
        "# Predict on dataset which model has not seen before \r\n",
        "print(knn.predict(X_test)) \r\n",
        "\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 2 1 1 0 1 2 2 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7hqoz-g4CGM",
        "outputId": "d1703a30-7e05-4f8d-f43f-8e9cdc1742a6"
      },
      "source": [
        "#naive bayes\r\n",
        "\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "\r\n",
        "X, y = load_iris(return_X_y=True)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\r\n",
        "gnb = GaussianNB()\r\n",
        "y_pred = gnb.fit(X_train, y_train).predict(X_test)\r\n",
        "print(\"Number of mislabeled points out of a total %d points : %d\"\r\n",
        "     % (X_test.shape[0], (y_test != y_pred).sum()))\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of mislabeled points out of a total 75 points : 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t--BN2Qb4Nrw",
        "outputId": "9a528231-32cf-43fc-fd6f-5d1a1555b5c8"
      },
      "source": [
        "#random forest\r\n",
        "\r\n",
        "# importing required libraries \r\n",
        "# importing Scikit-learn library and datasets package \r\n",
        "from sklearn import datasets \r\n",
        "\r\n",
        "# Loading the iris plants dataset (classification) \r\n",
        "iris = datasets.load_iris()\t \r\n",
        "print(iris.target_names) \r\n",
        "print(iris.feature_names)\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMgo2TAM4nc7"
      },
      "source": [
        "# dividing the datasets into two parts i.e. training datasets and test datasets \r\n",
        "X, y = datasets.load_iris( return_X_y = True) \r\n",
        "\r\n",
        "# Spliting arrays or matrices into random train and test subsets \r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "# i.e. 80 % training dataset and 30 % test datasets \r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.70) \r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsN8rVql4vGo"
      },
      "source": [
        "# importing random forest classifier from assemble module \r\n",
        "from sklearn.ensemble import RandomForestClassifier \r\n",
        "import pandas as pd \r\n",
        "# creating dataframe of IRIS dataset \r\n",
        "data = pd.DataFrame({'sepallength': iris.data[:, 0], 'sepalwidth': iris.data[:, 1], \r\n",
        "\t\t\t\t\t'petallength': iris.data[:, 2], 'petalwidth': iris.data[:, 3], \r\n",
        "\t\t\t\t\t'species': iris.target}) \r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhRrQ_Ss5MX7",
        "outputId": "b6667820-7a48-4166-e7fb-99aa7a79994a"
      },
      "source": [
        "# printing the top 5 datasets in iris dataset \r\n",
        "print(data.head()) \r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sepallength  sepalwidth  petallength  petalwidth  species\n",
            "0          5.1         3.5          1.4         0.2        0\n",
            "1          4.9         3.0          1.4         0.2        0\n",
            "2          4.7         3.2          1.3         0.2        0\n",
            "3          4.6         3.1          1.5         0.2        0\n",
            "4          5.0         3.6          1.4         0.2        0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddK_orWo5PEH",
        "outputId": "1cf83a28-a628-41fe-c2e7-26bf61669237"
      },
      "source": [
        "# creating a RF classifier \r\n",
        "clf = RandomForestClassifier(n_estimators = 100) \r\n",
        "\r\n",
        "# Training the model on the training dataset \r\n",
        "# fit function is used to train the model using the training sets as parameters \r\n",
        "clf.fit(X_train, y_train) \r\n",
        "\r\n",
        "# performing predictions on the test dataset \r\n",
        "y_pred = clf.predict(X_test) \r\n",
        "\r\n",
        "# metrics are used to find accuracy or error \r\n",
        "from sklearn import metrics \r\n",
        "print() \r\n",
        "\r\n",
        "# using metrics module for accuracy calculation \r\n",
        "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred)) \r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ACCURACY OF THE MODEL:  0.9523809523809523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU4woMH07kWC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}